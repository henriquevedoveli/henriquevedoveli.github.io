<!DOCTYPE HTML>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0RT4BLJBR8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0RT4BLJBR8');
</script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name=viewport content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta name="google-site-verification" content="XXjK99sZKdpFN8kxwbglvDK8Gbhanfx-QfZGGG_TU1M" />
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

  <title>Henrique Vedoveli</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:68%;vertical-align:middle">
              <p style="text-align:center">
                <name>Henrique Vedoveli</name>
                
              </p>
               <p>Currently working as a Machine Learning Enginner at <a href="pacerwm.com" target="_blank"> PACER</a>
                which aims to offer solutions that increases the efficiency of its clients' operations.
                <p>
                  <!-- trunk-ignore(git-diff-check/error) -->
                  <p>Also I'm doing Master's in Computer Science from <a href="https://www.prppg.ufpr.br/site/ppginf/pb/" target="_blank">UFPR-PPGInf</a> where I worked in the <a href=" http://www.imago.ufpr.br/" target="_blank">IMAGO</a> search group. 
                  </p>
                </p>
              <p>I obtained my Bachelor's Degree in Physics from <a href=" http://www.imago.ufpr.br/" target="_blank">UEM</a> in 2022.
              </p>

              <br>

              <p style="text-align:center">
                <a href="mailto:henriquevedoveli@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Akshay_Bhatia_CV.pdf" target="_blank">CV</a> &nbsp/&nbsp
                <a href="http://lattes.cnpq.br/2555473834351003" target="_blank">CV Lattes</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/henrique-vedoveli/" target="_blank">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/henrique-vedoveli" target="_blank">Github</a>
              </p>
            </td>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Main Interests</heading>

              <p>
                My interests broadly lie in the fields of Natural Language Processing, Machine Learning, and Computer Vision. More recently, I have been working at the intersection of Computer Vision and Natural Language Processing for visio-linguistic tasks such as Image Captioning and Visual Question Answering for Geospatial and Remote Sensing domain in a unsupervised/semi-supervised setting. 
              </p>
              <p> 
                Previously, my work focused on weakly-supervised <a href="https://www.aclweb.org/anthology/2021.naacl-srw.14/" target="_blank">text classification</a> and context aware and controlled <a href="https://doi.org/10.1017/S1351324921000474" target="_blank">text generation</a> algorithms for applications in the <a href="https://knorex.zendesk.com/hc/en-us/articles/4407119434137" target="_blank">Dynamic Creative Optimization</a> domain. 
              </p>
            </td>
          </tr>
        </tbody>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            <td width="100%" valign="middle">
              <heading>Education</heading>
            </td>
          </tr>
        </table>
    <table id="publications" width="100%" align="center" border="0" border-spacing="0" border-collapse="separate"
          cellspacing="0" cellpadding="20">

          <tr>
            <td width="25%" valign="top">
                  <img src='images/ufpr.png' width="200" height="150">
            </td>
            <td width="75%" valign="center">
              <a href="https://www.prppg.ufpr.br/site/ppginf/pb/" target="_blank">
                <papertitle>Ferderal University of Paraná</papertitle>
              </a>, <em>Curitiba, PR, Brazil</em>
              <br>
              <strong>Master's of Computer Science</strong>
              <br>
              Aug. 2022 - Currently
              <br>
              <strong>Thesis</strong><em>: Explainable Algorithm to Detect Psoriatic Arthritis in Thermal Imaging </em>
              <br>
              <abstract>
                <p> BLABLABLA</p>
              </abstract>
              <br>
            </td>
          </tr> 
          <tr>
            <td width="25%" valign="top">
                  <img src='images/uem.png' width="150" height="75" style="margin-left: 0.6em;">
            </td>
            <td width="75%" valign="center">
              <a href="http://www.uem.br/" target="_blank">
                <papertitle>State University of Maringá</papertitle>
              </a>, <em>Maringá, PR, Brazil</em>
              <br>
              <strong>Bachelors of Physics</strong> (January 2018 - July 2022)
              <br>
              <strong>Thesis</strong><em>: Classification of Pneumonia on Chest X-ray Using Convolutional Neural Networks</em>
              <br>
               Link to the presentation (pt-br) <a href="https://www.youtube.com/watch?v=xq9WjMdlgRI&ab_channel=HenriqueVedoveli" target="_blank">YouTube Video
              </a>
              <br>
            </td>
          </tr> 
      </table>

      <br>
      <br>
      <br>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            <td width="100%" valign="middle">
              <heading>Work Experience</heading>
            </td>
          </tr>
        </table>

                <table id="experience" width="100%" align="center" border="0" border-spacing="0" border-collapse="separate"
          cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td width="25%" valign="margin-right">
                  <img src='images/pacer.png' width="75", height="75">
            </td>
            <td swidth="75%" valign="center">
              <strong>Machine Learning Enginner</strong> (2022 - Currently)
              <br>     
              <em>PACER</em>
              <br>
              <br>
              <br>
            </td>
          </tr>    


          <td width="25%" valign="middle">
            <img src='images/uem.png' width="150", height="75">
      </td>
      <td swidth="75%" valign="center">
      <a href="" target="http://www.dfi.uem.br/fisicaold/site.dfi.uem.br/wp-content/uploads/2016/10/2887-F%C3%ADsica-Geral-III-Programa-2008.pdf">
        <papertitle>Physics IV - Modern Physics</papertitle>(2021- 2022)
      </a>
      <br>
      Teaching Assistant
      <br>      <em>State University of Maringá</em>
      <br>
      <br>
      <br>
    
      <a href="" target="http://www.dfi.uem.br/fisicaold/site.dfi.uem.br/wp-content/uploads/2016/10/2887-F%C3%ADsica-Geral-III-Programa-2008.pdf">
        <papertitle>Physics III - Electromagnetism</papertitle>(2020 - 2021)
      </a>
      <br>
      Teaching Assistant
      <br>
      <em>State University of Maringá</em>
      <br>
    </td>
     </table>

     <br>
     <br>
     <br>  

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            <td width="100%" valign="middle">
              <heading>Relevant Projects</heading>
            </td>
          </tr>
        </table>

        <table id="publications" width="100%" align="center" border="0" border-spacing="0" border-collapse="separate"
          cellspacing="0" cellpadding="20">

          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src='images/map.png' width="140" height="100">
            </td>
            <td width="75%" valign="center">
              <a href="data/ms_akshay_final.pdf" target="_blank">
                <papertitle>Improving Cross-View Remote Sensing Image Retrieval with Images and Captions
                </papertitle>
            </a>
              <br>
              <em>Masters Project</em>
              <br>
              <a href="data/ms_akshay_final.pdf" target="_blank">Report</a>
              <br>
              <p align="justify">
                <abstract>
Cross-View Remote Sensing Image Retrieval or cross-view geo-localization is a fundamental research area in remote sensing image analysis. It is used to determine the position of a ground image query by correlating it with a database of geo-tagged satellite images and is often used for several applications such as disaster and damage assessment and monitoring road and terrain network understanding. But a common challenge for this task is the significant variation in view angles and time differences between the ground-level image and the corresponding aerial image. As a result, it is very difficult to capture global semantics and other relations between the two image pairs. Recent research has made remarkable strides in remote-sensing image retrieval benchmarks but conventional methods often overlook other modalities such as textual captions which describe the entities and other information present in ground-level images.
                  <br>
                  <br>
We propose a new approach to enhance the cross-view image retrieval results by utilizing both images and associated textual captions depicting geographic content that describe the contents of the ground-level image. Our framework ex- tracts geographic content and terrain features from the ground-level image and text caption. Finally, we curate a new dataset based on an existing geographic image captioning dataset, GeoRic. We do this by scraping overhead imagery for the corresponding ground-level images in the dataset using Google Static Maps API. We then demonstrate the effectiveness of our multi-modal approach on the newly created dataset by comparing it with existing unimodal and multi-modal deep learning-based image retrieval methods. Experimental results show that our approach outperforms the traditional image retrieval method and performs competitively with an image-text retrieval model in terms of retrieval accuracy. The incorporation of captions improves retrieval performance, especially in cases where the images have complex and varied visual content. In summary, this project proposes an approach to enhance the remote sensing image retrieval results by utilizing both images and captions. The proposed approach can capture the complex relationships between the images and captions and achieves superior performance compared to traditional unimodal image retrieval methods.
              </abstract>
              </p>
            </td>
          </tr>


          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src='images/drone.png' width="140" height="100">
            </td>
            <td width="75%" valign="center">
              <a href="data/drone_fault_detection.pdf" target="_blank">
                <papertitle>Drone Fault Detection Based on ROS Topics
                </papertitle>
            </a>
              <br>
              <em>Course Project for EECS 283: Advanced Topics in Intelligent Systems with <a href="https://azinsh1988.github.io/AzinShamshirgaran/" target="_blank">Azin Shamshirgaran</a></em>
              <br>
              <a href="data/drone_fault_detection.pdf" target="_blank">Report</a>
              <br>
              <p align="justify">
                <abstract>
                  Explored the domain of external and internal fault detection systems for autonomous UAVs and drones. Main contributions included gathering and labeling of sensory data using a Parrot Bebop 2 drone and experimenting with variations of ordering techniques to enhance CNN models for 1D drone sensory data.
                  <br>
                  <br>
                  Improved vanilla CNNs using upsampled ordering for sensory data with inclusion of novel features, outperforming classical machine learning and existing heuristics' based algorithms with an AUC-ROC score of 94.3%.
              </abstract>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src='https://raw.githubusercontent.com/akshaybhatia10/RoadNetworkExtraction-MoveHack/master/assets/n.png' width="140" height="100">
            </td>
            <td width="75%" valign="center">
              <a href="https://github.com/akshaybhatia10/RoadNetworkExtraction-MoveHack" target="_blank">
                <papertitle>Road Network Extraction using Satellite Imagery
                </papertitle>
            </a>
              <br>
              <em>Submission for MoveHack Global Mobility Hackathon 2018</em>
              <br>
              <a href="https://github.com/akshaybhatia10/RoadNetworkExtraction-MoveHack" target="_blank">Github</a> / 
              <a href="https://www.youtube.com/watch?v=iX5_mabCocY" target="_blank">Demo video</a>
              <br>
              <p align="justify">
                <abstract>
                  The project involved training and deploying a road segmentation and extraction system using high-resolution satellite imagery for reliable and low-cost terrain monitoring and infrastructure quality assessment.
                  <br>
                  <br>
                  Optimized the trained model for real-time applications with final inference speed of only 0.28 seconds on Tesla K80 GPU achieving a mask accuracy of 95% and a dice score of 65% on the validation set.
              </abstract>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src='images/lingolens.png' width="140" height="100">
            </td>
            <td width="75%" valign="center">
            <a href="https://akshaybhatia10.github.io/lingolens.api/api-docs/" target="_blank">
                <papertitle>LingoLens
                </papertitle>
            </a>
              <br>
              <em>@<a href="https://campk12.com/" target="_blank">CampK12</a> with <a href="http://anshulbhagi.com/" target="_blank">Anshul Bhagi</a></em>
              <br>
              <a href="https://docs.google.com/presentation/d/1YmEspV94UykyZ23EJGJCXShHCSvlcj6lr3NkuRVEcyQ/edit?usp=sharing" target="_blank">Slides</a> / 
              <a href="https://akshaybhatia10.github.io/lingolens.api/api-docs/" target="_blank">API Docs</a>
              <br>
              <p align="justify">
                <abstract>
                  A multilingual language learning app for K12 students providing translations and transliterations for indoor and outdoor objects in over 20 languages.
                  <br>
                  <br>
                  We implemented a real-time object detection and on-device scene classification model Trained a custom YOLO model to detect ∼150 objects with an mAP of 67% improving the on-device detection and classification inference speeds by 19% with only 6% performance degradation compared to SoTA methods such as RetinaNet and SSD.
              </abstract>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src="images/book.png" width="140" height="100">
            </td>
            <td width="75%" valign="center">
              <a href="https://book-genre-classification.herokuapp.com/" target="_blank">
                <papertitle>Book Genre Classification
                </papertitle>
            </a>
              <br>
              <em>@<a href="http://www.spikewaysolutions.com/" target="_blank">Spikeway Technologies</a> with <a href="https://in.linkedin.com/in/praveenkkmrr" target="_blank">Praveen Kumar</a></em>
              <br>
              <a href="https://github.com/akshaybhatia10/Book-Genre-Classification" target="_blank">Github</a> /
              <a href="https://book-genre-classification.herokuapp.com/" target="_blank">Demo</a> 
              <br>
              <p align="justify">
                <abstract>
                  In this project, I led a 3 member team in the development of an ML-based system to classify books into their genres, based entirely on their title, without prior knowledge or context of author and origin.
                  <br>
                  <br>
                  I was responsible for the architecture, training, and deployment of the model. We improved the TFIDF and LR baselines by training a LSTM using pre-trained word2vec embeddings.
              </abstract>
              </p>
            </td>
          </tr>


          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src="images/cv.png" width="140" height="100">
            </td>
            <td width="75%" valign="center">
              <a href="https://github.com/akshaybhatia10/ComputerVision-Projects" target="_blank">
                <papertitle>Computer Vision Projects
                </papertitle>
            </a>
              <br>
              <em>Just for Fun</em>
              <br>
              <a href="https://github.com/akshaybhatia10/ComputerVision-Projects" target="_blank">Github</a>
              <br>
              <p align="justify">
                <abstract>
                  Open-source implementations for various computer vision tasks such as Template matching, Object Tracking, Face Swapper, Live Sketch, etc, using OpenCV.
                  <br>
                  <br>
                  100+ stars,  90+ forks.
              </abstract>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src='images/tc.png' width="140" height="100">
            </td>
            <td width="75%" valign="center">
              <a href="http://akshaybhatia10.herokuapp.com/" target="_blank">
                <papertitle>TravelCamp
                </papertitle>
            </a>
              <br>
              <em>Submission for IMAD 2016</em>
              <br>
              <a href="https://github.com/akshaybhatia10/imad-2016-app-heroku" target="_blank">Github</a> / 
              <a href="http://akshaybhatia10.herokuapp.com/" target="_blank">Demo</a>
              <br>
              <p align="justify">
                <abstract>
                  This project involved developing a social blog/profile web app where users can interact with each other. Other features including personal feed, posts, comments, signing, and logging in.
                  <br>
                  <br>
                  The web app follows RESTful approach for CRUD operations and was deployed using Heroku. Backend frameworks used: NodeJS, ExpressJS, MongoDB, PassportJS
                  
              </abstract>
              </p>
            </td>
          </tr>
      </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="2">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="1">
                  <a href="https://github.com/akshaybhatia10/" >More projects...</a>
                </font>
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  <a href="https://akshaybhatia10.github.io/"> Website template credits go to Akshay Bhatia.</a>
                </font>
              </p>
            </td>
          </tr>
        </table>
</body>

</html>
